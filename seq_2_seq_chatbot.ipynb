{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seq_2_seq_chatbot.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1P6SEPS9F3gnEh5Dxp7CV3Ai4J8aixeOQ",
      "authorship_tag": "ABX9TyMFHU5mWXSOfOZm4Xc7PVvn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anthonyhughes/chatbot_sequence2sequence/blob/main/seq_2_seq_chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import all neccessary resources"
      ],
      "metadata": {
        "id": "stdQiGPZfKUg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "id": "e2isktX3fPW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorlayer"
      ],
      "metadata": {
        "id": "4YJAD7EafWuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhvtTEyNfZ7P",
        "outputId": "162b9966-f2d8-462a-897a-3755986da550"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "JY9vACiPfG30"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorlayer as tl\n",
        "import numpy as np\n",
        "from tensorlayer.cost import cross_entropy_seq, cross_entropy_seq_with_mask\n",
        "from tqdm import tqdm\n",
        "from sklearn.utils import shuffle\n",
        "from tensorlayer.models.seq2seq import Seq2seq\n",
        "from tensorlayer.models.seq2seq_with_attention import Seq2seqLuongAttention\n",
        "import os\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PATH='drive/MyDrive/WVH/seq2seq_chatbot/'\n",
        "\n",
        "def load_data():\n",
        "    # read data control dictionaries\n",
        "    try:\n",
        "        with open(PATH + 'metadata.pkl', 'rb') as f:\n",
        "            metadata = pickle.load(f)\n",
        "    except Exception as e:\n",
        "      print(e)\n",
        "      metadata = None\n",
        "    # read numpy arrays\n",
        "    idx_q = np.load(PATH + 'idx_q.npy')\n",
        "    idx_a = np.load(PATH + 'idx_a.npy')\n",
        "    return metadata, idx_q, idx_a\n",
        "\n",
        "metadata, idx_q, idx_a = load_data()"
      ],
      "metadata": {
        "id": "I0fF-yAYf8i_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        " split data into train (70%), test (15%) and valid(15%)\n",
        "    return tuple( (trainX, trainY), (testX,testY), (validX,validY) )\n",
        "'''\n",
        "def split_dataset(x, y, ratio = [0.7, 0.15, 0.15] ):\n",
        "    # number of examples\n",
        "    data_len = len(x)\n",
        "    lens = [ int(data_len*item) for item in ratio ]\n",
        "\n",
        "    trainX, trainY = x[:lens[0]], y[:lens[0]]\n",
        "    testX, testY = x[lens[0]:lens[0]+lens[1]], y[lens[0]:lens[0]+lens[1]]\n",
        "    validX, validY = x[-lens[-1]:], y[-lens[-1]:]\n",
        "\n",
        "    return (trainX,trainY), (testX,testY), (validX,validY)\n",
        "\n",
        "split_set = split_dataset(idx_q, idx_a)"
      ],
      "metadata": {
        "id": "GmvyqngYhbBm"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initial_setup():\n",
        "    metadata, idx_q, idx_a = load_data()\n",
        "    (trainX, trainY), (testX, testY), (validX, validY) = split_dataset(idx_q, idx_a)\n",
        "    trainX = tl.prepro.remove_pad_sequences(trainX.tolist())\n",
        "    trainY = tl.prepro.remove_pad_sequences(trainY.tolist())\n",
        "    testX = tl.prepro.remove_pad_sequences(testX.tolist())\n",
        "    testY = tl.prepro.remove_pad_sequences(testY.tolist())\n",
        "    validX = tl.prepro.remove_pad_sequences(validX.tolist())\n",
        "    validY = tl.prepro.remove_pad_sequences(validY.tolist())\n",
        "    return metadata, trainX, trainY, testX, testY, validX, validY\n",
        "    \n",
        "#data preprocessing\n",
        "metadata, trainX, trainY, testX, testY, validX, validY = initial_setup()"
      ],
      "metadata": {
        "id": "11r7xXCjhJFI"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "src_len = len(trainX)\n",
        "tgt_len = len(trainY)\n",
        "\n",
        "assert src_len == tgt_len"
      ],
      "metadata": {
        "id": "_qF57jfqiSh3"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "n_step = src_len // batch_size\n",
        "src_vocab_size = len(metadata['idx2w']) # 8002 (0~8001)\n",
        "emb_dim = 1024"
      ],
      "metadata": {
        "id": "KEbF1IDEigvC"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word2idx = metadata['w2idx']   # dict  word 2 index\n",
        "idx2word = metadata['idx2w']   # list index 2 word\n",
        "unk_id = word2idx['unk']   # 1\n",
        "pad_id = word2idx['_']     # 0"
      ],
      "metadata": {
        "id": "jwTPu80EjN6l"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_id = src_vocab_size  # 8002\n",
        "end_id = src_vocab_size + 1  # 8003"
      ],
      "metadata": {
        "id": "RW4nfwZjjUIw"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word2idx.update({'start_id': start_id})\n",
        "word2idx.update({'end_id': end_id})\n",
        "idx2word = idx2word + ['start_id', 'end_id']\n",
        "src_vocab_size = tgt_vocab_size = src_vocab_size + 2\n",
        "num_epochs = 50\n",
        "vocabulary_size = src_vocab_size"
      ],
      "metadata": {
        "id": "F-EVF12XjGCK"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " def inference(seed, top_n):\n",
        "    model_.eval()\n",
        "    seed_id = [word2idx.get(w, unk_id) for w in seed.split(\" \")]\n",
        "    sentence_id = model_(inputs=[[seed_id]], seq_length=20, start_token=start_id, top_n = top_n)\n",
        "    sentence = []\n",
        "    for w_id in sentence_id[0]:\n",
        "        w = idx2word[w_id]\n",
        "        if w == 'end_id':\n",
        "            break\n",
        "        sentence = sentence + [w]\n",
        "    return sentence"
      ],
      "metadata": {
        "id": "FGGj61JTjkEE"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_seq_length = 20\n",
        "model_ = Seq2seq(\n",
        "        decoder_seq_length = decoder_seq_length,\n",
        "        cell_enc=tf.keras.layers.GRUCell,\n",
        "        cell_dec=tf.keras.layers.GRUCell,\n",
        "        n_layer=3,\n",
        "        n_units=256,\n",
        "        embedding_layer=tl.layers.Embedding(vocabulary_size=vocabulary_size, embedding_size=emb_dim),\n",
        "        )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdUEEACtFI8i",
        "outputId": "8d96865a-fd88-4d67-b877-e0d0fbb63937"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TL] Embedding embedding_1: (8004, 1024)\n",
            "[TL] RNN rnn_1: cell: GRUCell, n_units: 256\n",
            "[TL] RNN rnn_2: cell: GRUCell, n_units: 256\n",
            "[TL] RNN rnn_3: cell: GRUCell, n_units: 256\n",
            "[TL] RNN rnn_4: cell: GRUCell, n_units: 256\n",
            "[TL] RNN rnn_5: cell: GRUCell, n_units: 256\n",
            "[TL] RNN rnn_6: cell: GRUCell, n_units: 256\n",
            "[TL] Reshape reshape_1\n",
            "[TL] Dense  dense_1: 8004 No Activation\n",
            "[TL] Reshape reshape_2\n",
            "[TL] Reshape reshape_3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.optimizers.Adam(learning_rate=0.001)\n",
        "model_.train()"
      ],
      "metadata": {
        "id": "hpXSWJL2FLKA"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seeds = [\"how are you?\", \"donald trump is terrible\"]"
      ],
      "metadata": {
        "id": "9RbiPNFfFXGZ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_chatbot(trainX, trainY):\n",
        "      for epoch in range(num_epochs):\n",
        "        model_.train()\n",
        "        trainX, trainY = shuffle(trainX, trainY, random_state=0)\n",
        "        total_loss, n_iter = 0, 0\n",
        "        for X, Y in tqdm(tl.iterate.minibatches(inputs=trainX, targets=trainY, batch_size=batch_size, shuffle=False), \n",
        "                        total=n_step, desc='Epoch[{}/{}]'.format(epoch + 1, num_epochs), leave=False):\n",
        "\n",
        "            X = tl.prepro.pad_sequences(X)\n",
        "            _target_seqs = tl.prepro.sequences_add_end_id(Y, end_id=end_id)\n",
        "            _target_seqs = tl.prepro.pad_sequences(_target_seqs, maxlen=decoder_seq_length)\n",
        "            _decode_seqs = tl.prepro.sequences_add_start_id(Y, start_id=start_id, remove_last=False)\n",
        "            _decode_seqs = tl.prepro.pad_sequences(_decode_seqs, maxlen=decoder_seq_length)\n",
        "            _target_mask = tl.prepro.sequences_get_mask(_target_seqs)\n",
        "\n",
        "            with tf.GradientTape() as tape:\n",
        "                ## compute outputs\n",
        "                output = model_(inputs = [X, _decode_seqs])\n",
        "                \n",
        "                output = tf.reshape(output, [-1, vocabulary_size])\n",
        "                ## compute loss and update model\n",
        "                loss = cross_entropy_seq_with_mask(logits=output, target_seqs=_target_seqs, input_mask=_target_mask)\n",
        "\n",
        "                grad = tape.gradient(loss, model_.all_weights)\n",
        "                optimizer.apply_gradients(zip(grad, model_.all_weights))\n",
        "            \n",
        "            total_loss += loss\n",
        "            n_iter += 1\n",
        "\n",
        "        # printing average loss after every epoch\n",
        "        print('Epoch [{}/{}]: loss {:.4f}'.format(epoch + 1, num_epochs, total_loss / n_iter))"
      ],
      "metadata": {
        "id": "ULC6A5p4FhRX"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_chatbot(trainX, trainY)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UQTzskOFuJT",
        "outputId": "1f54851b-55b2-4b4d-d12d-9142865b316c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch[1/50]:  66%|██████▌   | 1887/2852 [53:14<28:12,  1.75s/it]"
          ]
        }
      ]
    }
  ]
}